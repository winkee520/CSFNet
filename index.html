
<!doctype html>
<html lang="en">

<head>
  <meta name="google-site-verification" content="ftFOlJETX-2KNjaPh8W6s8lhigItRuu9fOmjHZZ0nY0" />
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
    integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">

  <title>VisualTTS</title>
</head>
<style type="text/css">
  table {
    width: 100%;
    table-layout: fixed;
  }

  audio {
    width: 100%;
  }

  thead>tr>th:first-child {
    width: 96px;
  }

  @media (max-width: 767px) {
    .big-screen {
      display: none;
    }
  }

  @media (min-width: 767px) {
    .small-screen {
      display: none;
    }
  }
</style>




<body>
  <header class="header">
    <div class="jumbotron bg-secondary text-center">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-md-12">
 
            <h1><a class="text-light">Cepstral and spectral domains based fusion network <br> for robust speech enhancement </h1><br>   
             <font size=5><span style="color:#FFFFFF"> Anonymous submission to INTERSPEECH 2023 <br></font>
		 </a>  
            <p>
              <div class="row">
              </div>
            </p>
            
          </div>
        </div>
      </div>
    </div>
  </header>
  <main>
    <div class="container">
      <div class="row" id="result">
        <div class="col-md-12">
        	<h4>Abstract</h4>  
			Most mainstream speech enhancement solutions using deep neural networks (DNNs) focus on estimating a clean spectrum or waveform, while few studies have explored speech enhancement in the cepstral domain. In this study, we propose a cepstrum and spectrum fusion network to take advantage of both domain features in order to achieve better performance. Specifically, We use a Conformer-embedded SkipConvNet structure that employs homomorphic filtering to estimate the cepstrum of clean speech. We then apply inverse cepstral analysis to transfer the cepstrum to the spectrum for final fusion processing. Experimental results show that incorporating quefrency emphasis can enhance speech harmonics and attenuate reverberation more effectively than traditional spectral domain methods. We assess our model on the DNS challenge test set and naturalistic APOLLO Fearless Steps test sets.<br>
<br>
<div style="display: flex; flex-direction: row; justify-content: center; align-items: center;">
  <div style="text-align: center;margin-left: 40px;">
    <img src="systemoverflow.drawio.png" width="640" height="260">
    <p> <br><br>Fig. 1: The schematic workflow: <br>Input noisy speech waveform is transformed to cepstrum and spectrum domain features, and those features will be fed into SkipConvNet. Only SkipConvNet block and Fusion Net block are DNN modules</p>
  </div>
  <div style="text-align: center; margin-left: 60px;">
    <img src="SkipConvNet.drawio.png" width="450" height="280">
    <p> <br>Fig. 2: Model structure of SkipConvNet with conformer: convolutional encoding and decoding sturecture with Conformer module.</p>
  </div>
</div>
<br><br>

      <h4>Test Datasets</h4>
      <b>DNS-Challenge non-blind dataset [1]</b>: A synthetic data set contains 'with reverberation' and 'no reverberation' subsets. <br>
      <b>APOLLO Fearless Steps dataset [2]</b>: A naturalistic noisy data set with 8kHz sampling rate from Fearless Steps Challenge: Phase II. <br>

      <br><br>
    <h4> Audio Samples </h4>
    <hr class="hr_line">
    <h5>DNS-Challenge non-blind dataset</h5>
    <table class="table ">
      <thead>
          <tr>
              <th>Samples</th>
              <th>Noisy</th>
              <th>Clean</th>
              <th>DTLN [3]</th>
              <th>Cepstrum Enhance</th>
              <th>Fusion Net</th>
          </tr>
      </thead>
      <tbody>
        <tr> <td> Sample 1 </td>
          <td><audio controls=""><source src="NOISY/1.wav"></audio></td>
          <td><audio controls=""><source src="CLEAN/1.wav"></audio></td>
          <td><audio controls=""><source src="DTLN/1.wav"></audio></td>
          <td><audio controls=""><source src="Ceps/1.wav"></audio></td>
          <td><audio controls=""><source src="FUSION/1.wav"></audio></td>
        </tr>
        <tr> <td> Sample 2 </td>
          <td><audio controls=""><source src="NOISY/2.wav"></audio></td>
          <td><audio controls=""><source src="CLEAN/2.wav"></audio></td>
          <td><audio controls=""><source src="DTLN/2.wav"></audio></td>
          <td><audio controls=""><source src="Ceps/2.wav"></audio></td>
          <td><audio controls=""><source src="FUSION/2.wav"></audio></td>
        </tr>
        <tr> <td> Sample 3 </td>
          <td><audio controls=""><source src="NOISY/3.wav"></audio></td>
          <td><audio controls=""><source src="CLEAN/3.wav"></audio></td>
          <td><audio controls=""><source src="DTLN/3.wav"></audio></td>
          <td><audio controls=""><source src="Ceps/3.wav"></audio></td>
          <td><audio controls=""><source src="FUSION/3.wav"></audio></td>
        </tr>
        <tr> <td> Sample 4 </td>
          <td><audio controls=""><source src="NOISY/4.wav"></audio></td>
          <td><audio controls=""><source src="CLEAN/4.wav"></audio></td>
          <td><audio controls=""><source src="DTLN/4.wav"></audio></td>
          <td><audio controls=""><source src="Ceps/4.wav"></audio></td>
          <td><audio controls=""><source src="FUSION/4.wav"></audio></td>
        </tr>
        <tr> <td> Sample 5 </td>
          <td><audio controls=""><source src="NOISY/5.wav"></audio></td>
          <td><audio controls=""><source src="CLEAN/5.wav"></audio></td>
          <td><audio controls=""><source src="DTLN/5.wav"></audio></td>
          <td><audio controls=""><source src="Ceps/5.wav"></audio></td>
          <td><audio controls=""><source src="FUSION/5.wav"></audio></td>
        </tr>
        </tr>
    </tbody>
</table>
<hr class="hr_line">
<h5>APOLLO Fearless Steps dataset</h5>
<table class="table ">
  <thead>
      <tr>
          <th>Samples</th>
          <th>Noisy</th>
          <th>DTLN [3]</th>
          <th>Cepstrum Enhance</th>
          <th>Fusion Net</th>
      </tr>
  </thead>
  <tbody>
    <tr> <td> Sample 1 </td>
      <td><audio controls=""><source src="NOISY/FS02_ASR_track2_eval_01527.wav"></audio></td>
      <td><audio controls=""><source src="DTLN/FS02_ASR_track2_eval_01527.wav"></audio></td>
      <td><audio controls=""><source src="Ceps/FS02_ASR_track2_eval_01527.wav"></audio></td>
      <td><audio controls=""><source src="FUSION/FS02_ASR_track2_eval_01527.wav"></audio></td>
    </tr>
    <tr> <td> Sample 2 </td>
      <td><audio controls=""><source src="NOISY/FS02_ASR_track2_eval_00044.wav"></audio></td>
      <td><audio controls=""><source src="DTLN/FS02_ASR_track2_eval_00044.wav"></audio></td>
      <td><audio controls=""><source src="Ceps/FS02_ASR_track2_eval_00044.wav"></audio></td>
      <td><audio controls=""><source src="FUSION/FS02_ASR_track2_eval_00044.wav"></audio></td>
    </tr>
    <tr> <td> Sample 3 </td>
      <td><audio controls=""><source src="NOISY/FS02_ASR_track2_eval_00047.wav"></audio></td>
      <td><audio controls=""><source src="DTLN/FS02_ASR_track2_eval_00047.wav"></audio></td>
      <td><audio controls=""><source src="Ceps/FS02_ASR_track2_eval_00047.wav"></audio></td>
      <td><audio controls=""><source src="FUSION/FS02_ASR_track2_eval_00047.wav"></audio></td>
    </tr>
    <tr> <td> Sample 4 </td>
      <td><audio controls=""><source src="NOISY/FS02_ASR_track2_eval_00258.wav"></audio></td>
      <td><audio controls=""><source src="DTLN/FS02_ASR_track2_eval_00258.wav"></audio></td>
      <td><audio controls=""><source src="Ceps/FS02_ASR_track2_eval_00258.wav"></audio></td>
      <td><audio controls=""><source src="FUSION/FS02_ASR_track2_eval_00258.wav"></audio></td>
    </tr>
    <tr> <td> Sample 5 </td>
      <td><audio controls=""><source src="NOISY/FS02_ASR_track2_eval_02381.wav"></audio></td>
      <td><audio controls=""><source src="DTLN/FS02_ASR_track2_eval_02381.wav"></audio></td>
      <td><audio controls=""><source src="Ceps/FS02_ASR_track2_eval_02381.wav"></audio></td>
      <td><audio controls=""><source src="FUSION/FS02_ASR_track2_eval_02381.wav"></audio></td>
    </tr>
    </tr>
</tbody>
</table>
<h4> Spectrogram Samples </h4>
    <hr class="hr_line">
    <h5>DNS-Challenge non-blind dataset</h5>
    <img src="test.png" class="container">
    <hr class="hr_line">
    <h5>APOLLO Fearless Steps dataset</h5>
    <img src="apollo_spectro.png" class="container">
<hr class="hr_line">
<h4> References </h4>
[1] Reddy, Chandan K. A. et al. “The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results.” Interspeech (2020). <br>
[2] J. H. L. Hansen, A. Sangwan, A. Joglekar, A. E. Bulut, L. Kaushik, and C. Yu, “Fearless steps: Apollo-11 corpus advancements for speech technologies from earth to the moon,” in Interspeech, 2018<br>
[3] N. L. Westhausen and B. T. Meyer, “Dual-Signal Transformation LSTM Network for Real-Time Noise Suppression,” in Proc.Interspeech 2020
<br>
        
        
</div>
</div>